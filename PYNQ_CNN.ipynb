{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from driver import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myip = Model(\"bitstream/cnn.bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myip.debug=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data, check accuracy against software implementation\n",
    "data = np.int32(np.load(\"test_x.npy\"))\n",
    "gold = np.load(\"test_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "myip.setCNNWeights(np.load(\"CNN_weights.npy\"))\n",
    "myip.setCNNBias(np.load(\"CNN_bias.npy\"))\n",
    "myip.setDenseWeights(np.load(\"dense_weights.npy\"))\n",
    "myip.setDenseBias(np.load(\"dense_bias.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -5427,  -4580,   2832,  -1489,  -6022, -11662], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "data[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not confident enough to give prediction\n",
      "not confident enough to give prediction\n",
      "not confident enough to give prediction\n",
      "not confident enough to give prediction\n",
      "not confident enough to give prediction\n",
      "not confident enough to give prediction\n",
      "total time for 55200 inferences = 10.413133144378662\n",
      "Average inference time = 0.0001886962159820225\n",
      "Max inference frequency = 5299.237802027473\n",
      "Miss rate = 0.8152173913043478%\n",
      "[[162.   0.   0.   2.]\n",
      " [  1. 134.   3.   1.]\n",
      " [  0.  10. 226.   4.]\n",
      " [  0.   0.   1. 186.]]\n"
     ]
    }
   ],
   "source": [
    "myip.set_threshold(0.98)\n",
    "threshld_miss_count = 0\n",
    "confusion_matrix = np.zeros((4,4))\n",
    "\n",
    "start_time = time()\n",
    "for i in range(0, data.shape[0]):\n",
    "    \n",
    "#     print(\"-\"*40 + f\"Data: {i}\" + \"-\"*40)\n",
    "    gold_result = np.argmax(gold[i])\n",
    "    prediction_above_threshold = False\n",
    "    \n",
    "    for j in range(0, data.shape[1]):\n",
    "        \n",
    "        # run inference\n",
    "        predicted = myip.inference(data[i,j,:])\n",
    "        if predicted != -1:\n",
    "            prediction_above_threshold = True\n",
    "            break\n",
    "        \n",
    "    if prediction_above_threshold:\n",
    "        confusion_matrix[gold_result,predicted] += 1\n",
    "    else:\n",
    "        print(\"not confident enough to give prediction\")\n",
    "        threshld_miss_count += 1\n",
    "    myip.resetBuffer()\n",
    "\n",
    "print(f\"total time for {data.shape[0] * data.shape[1]} inferences = {time() - start_time}\")\n",
    "print(f\"Average inference time = {(time() - start_time)/(data.shape[0] * data.shape[1])}\")\n",
    "print(f\"Max inference frequency = {(data.shape[0] * data.shape[1])/(time() - start_time)}\")\n",
    "print(f\"Miss rate = {threshld_miss_count/data.shape[0]*100}%\")\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
