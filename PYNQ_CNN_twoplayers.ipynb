{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from driver import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myip = Model(\"bitstream/cnn.bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myip.debug=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data, check accuracy against software implementation\n",
    "data = np.int32(np.load(\"test_x.npy\"))\n",
    "gold = np.load(\"test_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "myip.setCNNWeights(np.load(\"CNN_weights.npy\"))\n",
    "myip.setCNNBias(np.load(\"CNN_bias.npy\"))\n",
    "myip.setDenseWeights(np.load(\"dense_weights.npy\"))\n",
    "myip.setDenseBias(np.load(\"dense_bias.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -5427  -4580   2832  -1489  -6022 -11662]\n",
      "736\n"
     ]
    }
   ],
   "source": [
    "# sample data\n",
    "print(data[0,0,:])\n",
    "# dataset size\n",
    "print(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player2 done\n",
      "total time for 12306 inferences = 10.077383518218994\n",
      "Average inference time = 0.0008190022471201783\n",
      "Max inference frequency = 1220.957146230013\n",
      "Miss rate = 0.0%\n",
      "[[154.   0.   0.   2.]\n",
      " [  1. 129.   3.   1.]\n",
      " [  0.   8. 221.   4.]\n",
      " [  0.   0.   1. 186.]]\n"
     ]
    }
   ],
   "source": [
    "myip.set_threshold(0.98)\n",
    "inference_count = 0\n",
    "threshld_miss_count = 0\n",
    "confusion_matrix = np.zeros((4,4))\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "player1_current_data_index = 0\n",
    "player1_current_inference_step = 0\n",
    "player1_predicted = 0\n",
    "player1_done = False\n",
    "player1_gold_result = np.argmax(gold[player1_current_data_index])\n",
    "player1_prediction_above_threshold = False\n",
    "\n",
    "player2_current_data_index = data.shape[0]//2\n",
    "player2_current_inference_step = 0\n",
    "player2_predicted = 0\n",
    "player2_done = False\n",
    "player2_gold_result = np.argmax(gold[player2_current_data_index])\n",
    "player2_prediction_above_threshold = False\n",
    "\n",
    "while not player1_done and not player2_done:\n",
    "    # player 1 part\n",
    "    if not player1_done:\n",
    "        # do inference\n",
    "#         print(f\"player 1 inferencing at {player1_current_data_index}, {player1_current_inference_step}\")\n",
    "        player1_predicted = myip.inference(data[player1_current_data_index,\\\n",
    "                                                player1_current_inference_step,\\\n",
    "                                                :], \\\n",
    "                                           user_number=0)\n",
    "        inference_count += 1\n",
    "        if player1_predicted != -1:\n",
    "            player1_prediction_above_threshold = True\n",
    "            player1_gold_result = np.argmax(gold[player1_current_data_index])\n",
    "            confusion_matrix[player1_gold_result,player1_predicted] += 1\n",
    "            player1_current_inference_step = data.shape[1]\n",
    "            \n",
    "        # prep for next inference\n",
    "        player1_current_inference_step += 1\n",
    "        if player1_current_inference_step >= data.shape[1]:\n",
    "            if not player1_prediction_above_threshold:\n",
    "                threshld_miss_count += 1\n",
    "            player1_current_data_index += 1\n",
    "            player1_current_inference_step = 0\n",
    "            myip.resetBuffer(user_number=0)\n",
    "        if player1_current_data_index == data.shape[0]//2:\n",
    "            print(\"player1 done\")\n",
    "            player1_done = True\n",
    "    \n",
    "    # player 2 part\n",
    "    if not player2_done:\n",
    "        # do inference\n",
    "#         print(f\"player 2 inferencing at {player2_current_data_index - data.shape[0]//2}, {player2_current_inference_step}\")\n",
    "        player2_predicted = myip.inference(data[player2_current_data_index,\\\n",
    "                                                player2_current_inference_step,\\\n",
    "                                                :], \\\n",
    "                                           user_number=1)\n",
    "        inference_count += 1\n",
    "        if player2_predicted != -1:\n",
    "            player2_prediction_above_threshold = True\n",
    "            player2_gold_result = np.argmax(gold[player2_current_data_index])\n",
    "            confusion_matrix[player2_gold_result,player2_predicted] += 1\n",
    "            player2_current_inference_step = data.shape[1]\n",
    "            \n",
    "        # prep for next inference\n",
    "        player2_current_inference_step += 1\n",
    "        if player2_current_inference_step >= data.shape[1]:\n",
    "            if not player2_prediction_above_threshold:\n",
    "                threshld_miss_count += 1\n",
    "            player2_current_data_index += 1\n",
    "            player2_current_inference_step = 0\n",
    "            myip.resetBuffer(user_number=1)\n",
    "        if player2_current_data_index == data.shape[0]:\n",
    "            print(\"player2 done\")\n",
    "            player2_done = True\n",
    "\n",
    "\n",
    "# for i in range(0, data.shape[0]):\n",
    "    \n",
    "# #     print(\"-\"*40 + f\"Data: {i}\" + \"-\"*40)\n",
    "#     gold_result = np.argmax(gold[i])\n",
    "#     prediction_above_threshold = False\n",
    "    \n",
    "#     for j in range(0, data.shape[1]):\n",
    "        \n",
    "#         # run inference\n",
    "#         predicted = myip.inference(data[i,j,:])\n",
    "#         inference_count += 1\n",
    "#         if predicted != -1:\n",
    "#             prediction_above_threshold = True\n",
    "#             break\n",
    "        \n",
    "#     if prediction_above_threshold:\n",
    "#         confusion_matrix[gold_result,predicted] += 1\n",
    "#     else:\n",
    "#         print(\"not confident enough to give prediction\")\n",
    "#         threshld_miss_count += 1\n",
    "#     myip.resetBuffer()\n",
    "\n",
    "print(f\"total time for {inference_count} inferences = {time() - start_time}\")\n",
    "print(f\"Average inference time = {(time() - start_time)/inference_count}\")\n",
    "print(f\"Max inference frequency = {inference_count/(time() - start_time)}\")\n",
    "print(f\"Miss rate = {threshld_miss_count/data.shape[0]*100}%\")\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
